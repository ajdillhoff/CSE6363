{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "\n",
    "Bagging, or bootstrap aggregating, is an ensemble method that involves training multiple iterations of the same model on different subsets of the training data. Specifically, the training data is randomly sampled with replacement to create multiple subsets. Each subset is used to train a model, and the final prediction is the average of the predictions of all models. This method is particularly useful for reducing overfitting and improving the stability and accuracy of the model. Since the model choice is the same for all iterations, the bias of the model is not reduced, but the variance is reduced. Bagging is commonly used with decision trees, as this notebook explores below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Path to dataset files: /home/alex/.cache/kagglehub/datasets/fedesoriano/heart-failure-prediction/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"fedesoriano/heart-failure-prediction\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df = pd.read_csv(path + \"/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "1   49   F           NAP        160          180          0     Normal    156   \n",
      "2   37   M           ATA        130          283          0         ST     98   \n",
      "3   48   F           ASY        138          214          0     Normal    108   \n",
      "4   54   M           NAP        150          195          0     Normal    122   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "1              N      1.0     Flat             1  \n",
      "2              N      0.0       Up             0  \n",
      "3              Y      1.5     Flat             1  \n",
      "4              N      0.0       Up             0  \n",
      "Number of positive samples: 508\n",
      "Number of negative samples: 410\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "# Split data into features and target\n",
    "X = df.drop(\"HeartDisease\", axis=1)\n",
    "y = df[\"HeartDisease\"]\n",
    "\n",
    "# Print number of positive versus negative samples\n",
    "print(\"Number of positive samples:\", np.sum(y == 1))\n",
    "print(\"Number of negative samples:\", np.sum(y == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0   40    0              1        140          289          0           0   \n",
      "1   49    1              2        160          180          0           0   \n",
      "2   37    0              1        130          283          0           1   \n",
      "3   48    1              3        138          214          0           0   \n",
      "4   54    0              2        150          195          0           0   \n",
      "\n",
      "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  \n",
      "0    172               0      0.0         0  \n",
      "1    156               0      1.0         1  \n",
      "2     98               0      0.0         0  \n",
      "3    108               1      1.5         1  \n",
      "4    122               0      0.0         0  \n"
     ]
    }
   ],
   "source": [
    "# Convert sex to numerical values\n",
    "X['Sex'] = X['Sex'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Convert chest pain type to numerical values\n",
    "X['ChestPainType'] = X['ChestPainType'].map({'TA': 0, 'ATA': 1, 'NAP': 2, 'ASY': 3})\n",
    "\n",
    "# Convert resting ECG to numerical values\n",
    "X['RestingECG'] = X['RestingECG'].map({'Normal': 0, 'ST': 1, 'LVH': 2})\n",
    "\n",
    "# Convert exercise angina to numerical values\n",
    "X['ExerciseAngina'] = X['ExerciseAngina'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "# Convert ST slope to numerical values\n",
    "X['ST_Slope'] = X['ST_Slope'].map({'Up': 0, 'Flat': 1, 'Down': 2})\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 660\n",
      "Validation samples: 74\n",
      "Test samples: 184\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Validation samples:\", X_val.shape[0])\n",
    "print(\"Test samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One model versus many\n",
    "\n",
    "If we want to make a fair comparison between a single model and an ensemble of models, we need to train a single model on the same data and figure out the hyperparameters that give the best performance.\n",
    "\n",
    "We set aside a small validation set above that we can use to compare the performance of the single model across varying depths. We will use the same validation set to compare the performance of the ensemble model. Once the best parameters are found, we can train the model on the entire training set and make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1, Accuracy: 0.8918918918918919\n",
      "Depth: 2, Accuracy: 0.8918918918918919\n",
      "Depth: 3, Accuracy: 0.918918918918919\n",
      "Depth: 4, Accuracy: 0.9054054054054054\n",
      "Depth: 5, Accuracy: 0.9324324324324325\n",
      "Depth: 6, Accuracy: 0.9324324324324325\n",
      "Depth: 7, Accuracy: 0.918918918918919\n",
      "Depth: 8, Accuracy: 0.9054054054054054\n",
      "Depth: 9, Accuracy: 0.9054054054054054\n",
      "Depth: 10, Accuracy: 0.9054054054054054\n",
      "Depth: 11, Accuracy: 0.9054054054054054\n",
      "Depth: 12, Accuracy: 0.918918918918919\n",
      "Depth: 13, Accuracy: 0.918918918918919\n",
      "Depth: 14, Accuracy: 0.918918918918919\n",
      "Depth: 15, Accuracy: 0.9054054054054054\n",
      "Depth: 16, Accuracy: 0.9054054054054054\n",
      "Depth: 17, Accuracy: 0.918918918918919\n",
      "Depth: 18, Accuracy: 0.918918918918919\n",
      "Depth: 19, Accuracy: 0.918918918918919\n",
      "Depth: 20, Accuracy: 0.9054054054054054\n",
      "Best depth: 5, Best accuracy: 0.9324324324324325\n",
      "Accuracy: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "# Determine the best single model based on depth\n",
    "best_depth = 0\n",
    "best_accuracy = 0\n",
    "for depth in range(1, 21):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, criterion='entropy')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Depth: {depth}, Accuracy: {accuracy}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"Best depth: {best_depth}, Best accuracy: {best_accuracy}\")\n",
    "\n",
    "# Train the best model\n",
    "X_combined = np.concatenate([X_train, X_val])\n",
    "y_combined = np.concatenate([y_train, y_val])\n",
    "clf = DecisionTreeClassifier(max_depth=best_depth)\n",
    "clf.fit(X_combined, y_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bagging pipeline using DecisionTreeClassifier\n",
    "np.random.seed(1337)\n",
    "num_models = 30\n",
    "max_depth = 10\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(num_models):\n",
    "    # Sample N random samples from the training set including y values with replacement\n",
    "    sample_indices = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "    X_train_sample = X_train.loc[sample_indices]\n",
    "    y_train_sample = y_train.loc[sample_indices]\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    model.fit(X_train_sample, y_train_sample)\n",
    "    models.append(model)\n",
    "\n",
    "# Predict using all models\n",
    "predictions = np.zeros((num_models, len(X_val)))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    predictions[i] = model.predict(X_val)\n",
    "\n",
    "# Determine the best number of models\n",
    "best_num_models = 0\n",
    "best_accuracy = 0\n",
    "for i in range(1, num_models + 1):\n",
    "    final_predictions = np.round(np.mean(predictions[:i], axis=0))\n",
    "    accuracy = accuracy_score(y_val, final_predictions)\n",
    "    print(f\"Number of models: {i}, Accuracy: {accuracy}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_num_models = i\n",
    "\n",
    "print(f\"Best number of models: {best_num_models}, Best accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the best configuration on the combined training and validation sets\n",
    "models = []\n",
    "\n",
    "for i in range(best_num_models):\n",
    "    # Sample N random samples from the training set including y values with replacement\n",
    "    sample_indices = np.random.choice(X_combined.index, size=len(X_combined), replace=True)\n",
    "    X_combined_sample = X_combined.loc[sample_indices]\n",
    "    y_combined_sample = y_combined.loc[sample_indices]\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    model.fit(X_combined_sample, y_combined_sample)\n",
    "    models.append(model)\n",
    "\n",
    "# Predict using all models\n",
    "predictions = np.zeros((best_num_models, len(X_test)))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    predictions[i] = model.predict(X_test)\n",
    "\n",
    "final_predictions = np.round(np.mean(predictions, axis=0))\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse4310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
