{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = np.array([\n",
    "    [1, 1],\n",
    "    [2, 1],\n",
    "    [2, 2],\n",
    "    [3, 2],\n",
    "    [3, 3]\n",
    "])\n",
    "\n",
    "y = np.array([1, 1, 0, 0, 1])\n",
    "\n",
    "learners = []\n",
    "weights = [np.ones(len(y)) / len(y)]\n",
    "alphas = []\n",
    "\n",
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Round 1\n",
    "weak_learner1 = DecisionTreeClassifier(max_depth=1)\n",
    "weak_learner1.fit(X, y, sample_weight=weights[0])\n",
    "learners.append(weak_learner1)\n",
    "\n",
    "# Print the feature chosen and threshold\n",
    "print(f\"Feature: {weak_learner1.tree_.feature[0]}\")\n",
    "print(f\"Threshold: {weak_learner1.tree_.threshold[0]}\")\n",
    "\n",
    "# Visualize the decision boundary with mlxtend\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X, y, weak_learner1)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted error\n",
    "y_pred = weak_learner1.predict(X)\n",
    "weighted_error = np.sum(weights * (y_pred != y))\n",
    "print(f\"Weighted Error: {weighted_error}\")\n",
    "\n",
    "# Compute the alpha\n",
    "alpha1 = np.log((1 - weighted_error) / weighted_error)\n",
    "alphas.append(alpha1)\n",
    "print(f\"Alpha: {alpha1}\")\n",
    "\n",
    "# Update the weights\n",
    "w2 = weights[0] * np.exp(alpha1 * (y != y_pred))\n",
    "w2 /= np.sum(w2)\n",
    "print(f\"Weights: {w2}\")\n",
    "weights.append(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Round 2\n",
    "weak_learner2 = DecisionTreeClassifier(max_depth=1)\n",
    "weak_learner2.fit(X, y, sample_weight=weights[1])\n",
    "learners.append(weak_learner2)\n",
    "\n",
    "# Print the feature chosen and threshold\n",
    "print(f\"Feature: {weak_learner2.tree_.feature[0]}\")\n",
    "print(f\"Threshold: {weak_learner2.tree_.threshold[0]}\")\n",
    "\n",
    "# Visualize the decision boundary with mlxtend\n",
    "plot_decision_regions(X, y, weak_learner2)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted error\n",
    "y_pred = weak_learner2.predict(X)\n",
    "weighted_error = np.sum(weights[1] * (y_pred != y))\n",
    "print(f\"Weighted Error: {weighted_error}\")\n",
    "\n",
    "# Compute the alpha\n",
    "alpha2 = np.log((1 - weighted_error) / weighted_error)\n",
    "alphas.append(alpha2)\n",
    "print(f\"Alpha: {alpha2}\")\n",
    "\n",
    "# Update the weights\n",
    "w3 = weights[1] * np.exp(alpha2 * (y != y_pred))\n",
    "w3 /= np.sum(w3)\n",
    "weights.append(w3)\n",
    "print(f\"Weights: {w3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Round 3\n",
    "weak_learner3 = DecisionTreeClassifier(max_depth=1)\n",
    "weak_learner3.fit(X, y, sample_weight=weights[2])\n",
    "learners.append(weak_learner3)\n",
    "\n",
    "# Print the feature chosen and threshold\n",
    "print(f\"Feature: {weak_learner3.tree_.feature[0]}\")\n",
    "print(f\"Threshold: {weak_learner3.tree_.threshold[0]}\")\n",
    "\n",
    "# Visualize the decision boundary with mlxtend\n",
    "plot_decision_regions(X, y, weak_learner3)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted error\n",
    "y_pred = weak_learner3.predict(X)\n",
    "weighted_error = np.sum(weights[2] * (y_pred != y))\n",
    "print(f\"Weighted Error: {weighted_error}\")\n",
    "\n",
    "# Compute the alpha\n",
    "alpha3 = np.log((1 - weighted_error) / weighted_error)\n",
    "alphas.append(alpha3)\n",
    "print(f\"Alpha: {alpha3}\")\n",
    "\n",
    "# Update the weights\n",
    "w4 = weights[2] * np.exp(alpha3 * (y != y_pred))\n",
    "w4 /= np.sum(w4)\n",
    "weights.append(w4)\n",
    "print(f\"Weights: {w4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Round 4\n",
    "weak_learner4 = DecisionTreeClassifier(max_depth=1)\n",
    "weak_learner4.fit(X, y, sample_weight=weights[3])\n",
    "learners.append(weak_learner4)\n",
    "\n",
    "# Print the feature chosen and threshold\n",
    "print(f\"Feature: {weak_learner4.tree_.feature[0]}\")\n",
    "print(f\"Threshold: {weak_learner4.tree_.threshold[0]}\")\n",
    "\n",
    "# Visualize the decision boundary with mlxtend\n",
    "plot_decision_regions(X, y, weak_learner4)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted error\n",
    "y_pred = weak_learner4.predict(X)\n",
    "weighted_error = np.sum(weights[3] * (y_pred != y))\n",
    "print(f\"Weighted Error: {weighted_error}\")\n",
    "\n",
    "# Compute the alpha\n",
    "alpha4 = np.log((1 - weighted_error) / weighted_error)\n",
    "alphas.append(alpha4)\n",
    "print(f\"Alpha: {alpha4}\")\n",
    "\n",
    "# Update the weights\n",
    "w5 = weights[3] * np.exp(alpha4 * (y != y_pred))\n",
    "w5 /= np.sum(w5)\n",
    "weights.append(w5)\n",
    "print(f\"Weights: {w5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Round 5\n",
    "weak_learner5 = DecisionTreeClassifier(max_depth=1)\n",
    "weak_learner5.fit(X, y, sample_weight=weights[4])\n",
    "learners.append(weak_learner5)\n",
    "\n",
    "# Print the feature chosen and threshold\n",
    "print(f\"Feature: {weak_learner5.tree_.feature[0]}\")\n",
    "print(f\"Threshold: {weak_learner5.tree_.threshold[0]}\")\n",
    "\n",
    "# Visualize the decision boundary with mlxtend\n",
    "plot_decision_regions(X, y, weak_learner5)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted error\n",
    "y_pred = weak_learner5.predict(X)\n",
    "weighted_error = np.sum(weights[4] * (y_pred != y))\n",
    "print(f\"Weighted Error: {weighted_error}\")\n",
    "\n",
    "# Compute the alpha\n",
    "alpha5 = np.log((1 - weighted_error) / weighted_error)\n",
    "alphas.append(alpha5)\n",
    "print(f\"Alpha: {alpha5}\")\n",
    "\n",
    "# Update the weights\n",
    "w6 = weights[4] * np.exp(alpha5 * (y != y_pred))\n",
    "w6 /= np.sum(w6)\n",
    "weights.append(w6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final classifier class to use with mlxtend\n",
    "class AdaBoost:\n",
    "    def __init__(self, learners, alphas):\n",
    "        self.learners = learners\n",
    "        self.alphas = alphas\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.array([learner.predict(X) for learner in self.learners])\n",
    "        preds = np.dot(self.alphas, preds) / np.sum(self.alphas)\n",
    "        return (preds > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final classifier\n",
    "clf = AdaBoost(learners, alphas)\n",
    "\n",
    "# Get final predictions\n",
    "y_pred = clf.predict(X)\n",
    "print(f\"Predictions: {y_pred}\")\n",
    "\n",
    "# Get final accuracy\n",
    "accuracy = np.sum(y_pred == y) / len(y)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Visualize the decision boundary with mlxtend\n",
    "plot_decision_regions(X, y, clf)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()\n",
    "\n",
    "# Print alphas\n",
    "print(f\"Alphas: {alphas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to sklearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=5, algorithm='SAMME')\n",
    "clf.fit(X, y)\n",
    "plot_decision_regions(X, y, clf)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
    "plt.show()\n",
    "\n",
    "# Get final predictions\n",
    "y_pred = clf.predict(X)\n",
    "print(f\"Predictions: {y_pred}\")\n",
    "\n",
    "# Get the alphas\n",
    "print(f\"Alphas: {clf.estimator_weights_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6363",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
