{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ajdillhoff/CSE6363/blob/main/imdb-rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhRTOlWxKAZK",
    "outputId": "d4e2339d-9446-4fea-c5ca-3b5c11c86451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext.transforms as T\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !pip install torchtext==0.12.0\n",
    "# !pip install torchdata\n",
    "# !pip install pytorch-lightning\n",
    "\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qk6li4p3KNX1"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "class RNN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,\n",
    "                 train_datapipe, val_datapipe, test_datapipe, batch_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Required since our input vector represents each word as an index into\n",
    "        # the vocabulary.\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=1)\n",
    "        # Creates an RNN using tanh by default.\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # LightningModule attributes\n",
    "        self.lr = 1e-3\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Datasets\n",
    "        self.train_datapipe = train_datapipe\n",
    "        self.val_datapipe = val_datapipe\n",
    "        self.test_datapipe = test_datapipe\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input = batch[\"token_ids\"].cuda()\n",
    "        target = torch.tensor(batch[\"target\"], dtype=torch.float).cuda()\n",
    "        output = self(input).squeeze()\n",
    "        loss = self.loss_fn(output, target)\n",
    "        acc = binary_accuracy(output, target)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input = batch[\"token_ids\"].cuda()\n",
    "        target = torch.tensor(batch[\"target\"], dtype=torch.float).cuda()\n",
    "        output = self(input).squeeze()\n",
    "        loss = self.loss_fn(output, target)\n",
    "        acc = binary_accuracy(output, target)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader = torch.utils.data.DataLoader(self.train_datapipe,\n",
    "                                             batch_size=None,\n",
    "                                             num_workers=8,\n",
    "                                             shuffle=True)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        loader = torch.utils.data.DataLoader(self.val_datapipe,\n",
    "                                             batch_size=None,\n",
    "                                             num_workers=8,\n",
    "                                             shuffle=False)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        loader = torch.utils.data.DataLoader(self.test_datapipe,\n",
    "                                             batch_size=None,\n",
    "                                             num_workers=8,\n",
    "                                             shuffle=False)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7J5W5j63rMe8"
   },
   "source": [
    "Our model works with numerical input. So, we'll need to convert each word into a corresponding one-hot vector based on the vocabulary of our dataset.\n",
    "\n",
    "Luckily, `torchtext` makes this simple by providing `build_vocab_from_iterator`. All we need to do is supply the `datapipe` iterator and it builds a vocabulary for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ofrugWLRsglO"
   },
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "max_tokens = 25000\n",
    "\n",
    "def make_vocabulary():\n",
    "    train_dataset = torchtext.datasets.SST2(split=\"train\")\n",
    "    train_datapipe = train_dataset.map(lambda x: tokenizer(x[0]))\n",
    "    v = torchtext.vocab.build_vocab_from_iterator(train_datapipe, specials=[\"<unk>\"], max_tokens=max_tokens)\n",
    "    v.set_default_index(0)\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxbKIcLnOiMQ",
    "outputId": "7a9382e0-7dca-4089-b808-573665ddc425"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cse6363/lib/python3.7/site-packages/torch/utils/data/datapipes/utils/common.py:25: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  \"Lambda function is not supported for pickle, please use \"\n",
      "/home/alex/anaconda3/envs/cse6363/lib/python3.7/site-packages/torch/utils/data/datapipes/iter/selecting.py:54: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\"Lambda function is not supported for pickle, please use \"\n"
     ]
    }
   ],
   "source": [
    "v = make_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdbOfF50uGyM"
   },
   "source": [
    "To finish preparing the data, the labels `pos` and `neg` should be converted to numeric values as well. This can be done with `LabelToIndex`.\n",
    "\n",
    "With the transforms in place, we can pass the `datapipe` to a PyTorch `DataLoader` object for use during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.VocabTransform(v),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    "    T.ToTensor(padding_value=padding_idx)\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_datapipe = torchtext.datasets.SST2(split='train')\n",
    "val_datapipe = torchtext.datasets.SST2(split='dev')\n",
    "test_datapipe = torchtext.datasets.SST2(split='test')\n",
    "\n",
    "train_datapipe = train_datapipe.map(lambda x: (tokenizer(x[0]), x[1]))\n",
    "train_datapipe = train_datapipe.batch(batch_size).rows2columnar([\"text\", \"label\"])\n",
    "train_datapipe = train_datapipe.map(lambda x: {\"token_ids\": text_transform(x[\"text\"]), \"target\": x[\"label\"]})\n",
    "\n",
    "val_datapipe = val_datapipe.map(lambda x: (tokenizer(x[0]), x[1]))\n",
    "val_datapipe = val_datapipe.batch(batch_size).rows2columnar([\"text\", \"label\"])\n",
    "val_datapipe = val_datapipe.map(lambda x: {\"token_ids\": text_transform(x[\"text\"]), \"target\": x[\"label\"]})\n",
    "\n",
    "test_datapipe = test_datapipe.map(lambda x: (tokenizer(x[0]), x[1]))\n",
    "test_datapipe = test_datapipe.batch(batch_size).rows2columnar([\"text\", \"label\"])\n",
    "test_datapipe = test_datapipe.map(lambda x: {\"token_ids\": text_transform(x[\"text\"]), \"target\": x[\"label\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOe99RCbvmLO"
   },
   "source": [
    "Create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EABdlqCowM-K"
   },
   "outputs": [],
   "source": [
    "model = RNN(len(v), 100, 256, 1, train_datapipe, val_datapipe, test_datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "referenced_widgets": [
      "f1b727b4a33a4b049c4472dea96cf01f",
      "9ef9785e81494f0e9a5b5b765889aa8d",
      "6ac150e8c9ad4a54b09843491a072806",
      "ac06aee8669e455a9b152e7c025dc325",
      "10c852625f374858810a6960a015ab33",
      "45026d33b4bd4598bd5435930c42a697",
      "21e1b90eeb994dee8a5044bc7775708b",
      "d530833c055b4fdb9e6c3cbbfdb5b644",
      "30710a486d114c57a87762ef5a92a164",
      "a009a6b3ccfa4f079d0a0f91f9b210b5",
      "afdfb74521d644fabeb8f741694b00e2"
     ]
    },
    "id": "oBBwjWcGwVpr",
    "outputId": "d40e129f-c344-44fb-f313-a3a85caa05c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | embedding | Embedding         | 1.4 M \n",
      "1 | rnn       | LSTM              | 366 K \n",
      "2 | fc        | Linear            | 257   \n",
      "3 | loss_fn   | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cse6363/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34c82f4fc434bbebe14722e1751435d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cse6363/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n",
      "/home/alex/anaconda3/envs/cse6363/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:727: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", callbacks=[checkpoint_callback], max_epochs=5)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPWAzYRiwdGzgFMG6EYGdUq",
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:cse6363] *",
   "language": "python",
   "name": "conda-env-cse6363-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10c852625f374858810a6960a015ab33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "21e1b90eeb994dee8a5044bc7775708b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30710a486d114c57a87762ef5a92a164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45026d33b4bd4598bd5435930c42a697": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ac150e8c9ad4a54b09843491a072806": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d530833c055b4fdb9e6c3cbbfdb5b644",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30710a486d114c57a87762ef5a92a164",
      "value": 1
     }
    },
    "9ef9785e81494f0e9a5b5b765889aa8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45026d33b4bd4598bd5435930c42a697",
      "placeholder": "​",
      "style": "IPY_MODEL_21e1b90eeb994dee8a5044bc7775708b",
      "value": "Epoch 0: "
     }
    },
    "a009a6b3ccfa4f079d0a0f91f9b210b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac06aee8669e455a9b152e7c025dc325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a009a6b3ccfa4f079d0a0f91f9b210b5",
      "placeholder": "​",
      "style": "IPY_MODEL_afdfb74521d644fabeb8f741694b00e2",
      "value": " 60/? [01:19&lt;00:00,  1.32s/it, loss=0.00038, v_num=0]"
     }
    },
    "afdfb74521d644fabeb8f741694b00e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d530833c055b4fdb9e6c3cbbfdb5b644": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b727b4a33a4b049c4472dea96cf01f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ef9785e81494f0e9a5b5b765889aa8d",
       "IPY_MODEL_6ac150e8c9ad4a54b09843491a072806",
       "IPY_MODEL_ac06aee8669e455a9b152e7c025dc325"
      ],
      "layout": "IPY_MODEL_10c852625f374858810a6960a015ab33"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
